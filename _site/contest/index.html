<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1,minimum-scale=1.0,maximum-scale=1.0,user-scalable=no"> <meta name="author" content="Oleh Zasadnyy, GDG Lviv"> <meta name="description" content="Hyperspectral Object Tracking Challenge 2022"> <meta name="keywords" content="event, gdg, devfest, google, programming, android, chrome, developers, lviv"> <meta name="google-site-verification" content="b9imDOrFawXaBXCC4r3uJDdswSYcalD-wWpMYhFq-no" /> <link rel="canonical" href="http://localhost:4000"> <!-- Social: Twitter --> <!-- <meta name="twitter:card" content="summary"> <meta name="twitter:site" content="@DevFest"> <meta name="twitter:title" content="Dataset and Protocol"> <meta name="twitter:description" content="Hyperspectral Object Tracking Challenge 2022"> <meta name="twitter:image:src" content="http://localhost:4000/img/seo/sharing-twitter.png"> --><!-- Social: Facebook / Open Graph --> <meta property="og:title" content="Dataset and Protocol" /> <meta property="og:site_name" content="Hyperspectral Object Tracking Challenge 2022" /> <meta property="og:type" content="website" /> <meta property="og:url" content="http://localhost:4000" /> <meta property="og:image" content="http://localhost:4000/img/seo/sharing-facebook.png" /> <meta property="og:description" content="Hyperspectral Object Tracking Challenge 2022" /> <title>Hyperspectral Object Tracking Challenging 2022</title> <!-- <link rel="shortcut icon" href="/img/favicons/favicon.ico"> <link rel="apple-touch-icon" sizes="152x152" href="/img/favicons/apple-touch-icon-152x152.png"> <link rel="apple-touch-icon" sizes="144x144" href="/img/favicons/apple-touch-icon-144x144.png"> <link rel="apple-touch-icon" sizes="120x120" href="/img/favicons/apple-touch-icon-120x120.png"> <link rel="apple-touch-icon" sizes="114x114" href="/img/favicons/apple-touch-icon-114x114.png"> <link rel="apple-touch-icon" sizes="76x76" href="/img/favicons/apple-touch-icon-76x76.png"> <link rel="apple-touch-icon" sizes="72x72" href="/img/favicons/apple-touch-icon-72x72.png"> <link rel="apple-touch-icon" sizes="60x60" href="/img/favicons/apple-touch-icon-60x60.png"> <link rel="apple-touch-icon" sizes="57x57" href="/img/favicons/apple-touch-icon-57x57.png"> <link rel="icon" type="image/png" href="/img/favicons/favicon-196x196.png"> <link rel="icon" type="image/png" href="/img/favicons/favicon-160x160.png"> <link rel="icon" type="image/png" href="/img/favicons/favicon-96x96.png"> <link rel="icon" type="image/png" href="/img/favicons/favicon-32x32.png"> <link rel="icon" type="image/png" href="/img/favicons/favicon-16x16.png"> <meta name="msapplication-TileColor" content="#2b5797"> <meta name="msapplication-TileImage" content="/img/favicons/mstile-144x144.png"> <meta name="msapplication-config" content="/img/favicons/browserconfig.xml"> --> <meta name="theme-color" content="#2b5797"> <link href="/css/main.css" rel="stylesheet"> <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries --> <!-- WARNING: Respond.js doesn't work if you view the page via file:// --> <!-- [if lt IE 9]> <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script> <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script> <![endif] --> <script> var _hmt = _hmt || []; (function() { var hm = document.createElement("script"); hm.src = "https://hm.baidu.com/hm.js?af09152a7488c83982c18e99d9c113e0"; var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s); })(); </script> </head> <body> <div id="preloader" class="preloader"> <div class="loader-gplus"></div> </div> <div id="st-container" class="st-container disable-scrolling"> <div class="st-pusher"> <div class="st-content"> <!-- Begin Top Section --> <section id="top-section" class="top-section image-section enable-overlay" style="background-image: url('/img/sections-background/Roma.jpeg');"> <div class="overlay gradient-overlay"></div> <header id="top-header" class="top-header"> <div class="overlay white-solid"></div> <svg id="menu-trigger" class="menu-trigger icon icon-menu visible-xs" viewBox="0 0 32 32"> <use xlink:href="/img/sprites/sprites.svg#icon-menu"></use> </svg> <a href="/" id="logo-header" class="logo-header"> <div class="logo logo-light"></div> </a> <!-- <div class="overlay white-solid"></div> <svg id="menu-trigger" class="menu-trigger icon icon-menu visible-xs" viewBox="0 0 32 32"> <use xlink:href="/img/sprites/sprites.svg#icon-menu"></use> <use xlink:href="/img/sprites/logos.png"></use> </svg> <a href="/" id="logo-header" class="logo-header"> <div class="logo logo-light"></div> </a> --> <nav class="st-menu st-effect" id="menu"> <div class="logo-navbar logo logo-dark visible-xs"></div> <ul> <li> <a class="" href=" / " >Home</a> </li> <li> <a class="current" href=" /contest/ " >Contest</a> </li> <li> <a class="" href=" /result/ " >Results</a> </li> </ul> <ul id="bottom-navlinks" class="bottom-navlinks visible-xs"> <li> <a href=" http://www.ieee-whispers.com/paper-submission/ " target="_blank">Submit your paper</a> </li> </ul> <a href=" http://www.ieee-whispers.com/paper-submission/ " class="right-nav-button right-nav-button-hidden btn btn-primary waves-effect waves-button waves-light waves-float pull-right hidden-xs hidden-sm" target="_blank"> Submit your paper </a> </nav> </header> <div class="content-wrapper"> <div class="jumbotron text-left"> <div class="animated hiding" data-animation="fadeInLeft" data-delay="500"> <h1>Dataset and Protocol</h1> </div> </div> </div> </section> <!-- Begin Blog--> <section id="blog" class="blog"> <div class="content-wrapper text-justify"> <div class="col-md-10 col-sm-10 col-lg-offset-2 col-md-offset-0 col-sm-offset-2"> <div class="col-lg-10 col-lg-offset-0"> <!-- <h4 style="text-align: center; font-size: 35.625px; ">Dataset</h4> --> <article class="row post"> <p class="post-body">The dataset used in this contest was acquired using a XIMEA snapshot VIS camera. The videos were captured at 25 frames per second (FPS). Each frame was originally captured in 2D with 16 bands arranged in a mosaic mode. Each frame is then converted to 3D with the first two dimensions index the location of each pixel, and the third dimension indexes the band number (code provided). The 16 bands cover the range from 470nm to 620nm, and each band image originally consists of 512Ã—256 pixels. RGB videos were also acquired at the same frame rate in a view point very close to the hyperspectral videos. False-color videos generated from the hyperspectral videos are also provided. The first frames of testing dataset are as follows:</p> </article> <article class="row post"> <style> table.dataintable { margin-top:15px; border:none; width:100%; margin: 0 auto text-align:center; } table.dataintable th { vertical-align:baseline; padding:5px 5px 5px 5px; background-color:#F5F5F5; border:none; text-align:center; color:rgba(0,0,0,0.8); } table.dataintable td { vertical-align:text-top; padding:6px 6px 6px 6px; border:none; } td img{ width: 170px; height:100px; } tr.name td { text-align: center; font-size: 14pt; font-weight: 300; } </style> <table width="95%" class="dataintable" align="center"> <tr> <td class="tracker"><img src="/img/dataset/ball.jpg"/></td> <td><img src="/img/dataset/basketball.jpg"/></td> <td><img src="/img/dataset/board.jpg"/></td> <td><img src="/img/dataset/book.jpg"/></td> <td><img src="/img/dataset/bus.jpg"/></td> </tr> <tr class="name"> <td>ball</td> <td>basketball</td> <td>board</td> <td>book</td> <td>bus</td> </tr> <tr> <td class="tracker"><img src="/img/dataset/bus2.jpg"/></td> <td><img src="/img/dataset/campus.jpg"/></td> <td><img src="/img/dataset/car.jpg"/></td> <td><img src="/img/dataset/car2.jpg"/></td> <td><img src="/img/dataset/car3.jpg"/></td> </tr> <tr class="name"> <td>bus2</td> <td>campus</td> <td>car</td> <td>car2</td> <td>car3</td> </tr> <tr> <td class="tracker"><img src="/img/dataset/card.jpg"/></td> <td><img src="/img/dataset/coin.jpg"/></td> <td><img src="/img/dataset/coke.jpg"/></td> <td><img src="/img/dataset/drive.jpg"/></td> <td><img src="/img/dataset/excavator.jpg"/></td> </tr> <tr class="name"> <td>card</td> <td>coin</td> <td>coke</td> <td>drive</td> <td>excavator</td> </tr> <tr> <td class="tracker"><img src="/img/dataset/face.jpg"/></td> <td><img src="/img/dataset/face2.jpg"/></td> <td><img src="/img/dataset/forest.jpg"/></td> <td><img src="/img/dataset/forest2.jpg"/></td> <td><img src="/img/dataset/fruit.jpg"/></td> </tr> <tr class="name"> <td>face</td> <td>face2</td> <td>forest</td> <td>forest2</td> <td>fruit</td> </tr> <tr> <td class="tracker"><img src="/img/dataset/hand.jpg"/></td> <td><img src="/img/dataset/kangaroo.jpg"/></td> <td><img src="/img/dataset/paper.jpg"/></td> <td><img src="/img/dataset/pedestrian.jpg"/></td> <td><img src="/img/dataset/pedestrian2.jpg"/></td> </tr> <tr class="name"> <td>hand</td> <td>kangaroo</td> <td>paper</td> <td>pedestrian</td> <td>pedestrian2</td> </tr> <tr> <td class="tracker"><img src="/img/dataset/player.jpg"/></td> <td><img src="/img/dataset/playground.jpg"/></td> <td><img src="/img/dataset/rider1.jpg"/></td> <td><img src="/img/dataset/rider2.jpg"/></td> <td><img src="/img/dataset/rubik.jpg"/></td> </tr> <tr class="name"> <td>player</td> <td>playground</td> <td>rider1</td> <td>rider2</td> <td>rubik</td> </tr> <tr> <td class="tracker"><img src="/img/dataset/student.jpg"/></td> <td><img src="/img/dataset/toy1.jpg"/></td> <td><img src="/img/dataset/toy2.jpg"/></td> <td><img src="/img/dataset/truck.jpg"/></td> <td><img src="/img/dataset/worker.jpg"/></td> </tr> <tr class="name"> <td>student</td> <td>toy1</td> <td>toy2</td> <td>truck</td> <td>worker</td> </tr> </table> </article> <article class="row post"> <h5>Dataset and Source Code Links</h5> <p class="post-body"><strong>Dataset Link</strong>: the dataset can be accessed via <a id= "google" href="https://drive.google.com/drive/folders/1lVP3BSuv_GuvQ5tWEtVc4_0bRCg4qKMx?usp=sharing" onclick="_hmt.push(['_trackEvent', 'datasetGoogle', 'click', 'datasetGoogle'])">Google Drive</a> or <a id= "baidu" href="https://pan.baidu.com/s/1FY2L6L9SDKw-V-bUkuosSA" onclick="_hmt.push(['_trackEvent', 'datasetBaidu', 'click', 'datasetBaidu'])">Baidu YunPan</a> Access code: n616</p> <p class="post-body"><strong>Evaluation code</strong>: <a href="/assets/code/Evaluation.zip">Evaluation.zip</a></p> <p class="post-body"><strong>2D image to hyperspectral cube conversion code</strong>: <a href="/assets/code/X2Cube.zip">X2Cube.zip</a></p> <p class="post-body"><strong>Python code for X2Cube and Evaluation <a href="/assets/code/HyperTools.py">HyperTools.py</a> </strong></p> <!-- <p class="post-body" style="color: red"><strong>The <i>car3</i>, <i>basketball</i> sequences in training the <i>car3</i> sequence in testing are corrected.</strong></p> --> </article> <article class="row post"> <h5 style="">Preprocessing</h5> <h5></h5> <h6 style="font-size: 20px;font-style: italic;">Camera Calibration</h6> <p class="post-body">The camera calibration process involves two steps: dark calibration and spectral correction. Dark calibration aims to remove the influence of noise produced by the camera sensor. It is done by subtracting a dark frame from the captured image, for which the dark frame was captured with lens covered by a cap. The goal of spectral calibration is to reduce the distortion of spectral responses. It is done by applying a sensor-specific spectral correction matrix on the measurement in each pixel. The 16 band images of the corrected hyperspectral data cube are saved as 2D frames with the 16 bands arranged again in a mosaic mode. </p> <h6 style="font-size: 20px;font-style: italic;">Image Registration</h6> <p class="post-body">The hyperspectral sequences and color sequences are registered to make them describe almost the same scene. This is done by manually selecting matching points in the first frame of both hyperspectral and color videos and then calculating geometrical transformation. The resulted transformation matrix was applied to all subsequent color frames to make alignment with the corresponding hyperspectral frames.</p> <h6 style="font-size: 20px;font-style: italic;">Image Conversion</h6> <p class="post-body">To ensure fair comparison, the hyperspectral videos were converted to false color videos using CIE color matching functions. This produces strictly spatially aligned hyperspectral and false-color videos.</p> <p class="post-body"> For details on the above steps, please refer to: F. Xiong, J. Zhou, and Y. Qian. "Material based object tracking in hyperspectral videos", IEEE Trans. Image Process., vol. 29, no. 1, pp. 3719-3733, 2020.</p> </article> <article class="row post"> <h5>Annotation</h5> <p class="post-body">A single upright bounding box is provided for the location of the target object in each frame. The bounding box is represented by the centre location and its height and width. The labels for hyperspectral and color videos were generated independently. The labels for the hyperspectral videos can be used directly on the false-color videos.</p> </article> <article class="row post"> <h5>Attributes</h5> <p class="post-body">The whole dataset contains 40 sets of videos for training and 35 sets of videos for testing. Every video is labelled with associated challenging factors out of eleven attributes, including illumination variation, scale variation, occlusion , deformation, motion blur, fast motion, in-plane rotation, out-of-plane rotation, out-of-view , background clutters, and low resolution.</p> </article> </div> <div class="col-lg-10 col-lg-offset-0"> <article class="row post"> <h5>Protocols:</h5> <p class="post-body"> <ul> <li>The use of the training set is optional.</li> <li>Tracking starts from the first frame of the sequence. The bounding box in the first frame are used to initialize the location of tracking. Single object tracking is expected.</li> <li>The same model hyper-parameters shall be used for all the sequences. </li> <li>The tracking results contain a sequence of bounding boxes for each frame. </li> </ul> </p> <h5></h5> <h5 style="">Evaluation Metrics</h5> <p class="post-body">Precision plot, success plot and area under curve (AUC) will be used to calculate the performance of all the trackers. Precision plot records the fractions of frames whose estimated location is within a given distance threshold to the ground truth. The average distance precision rate is reported at a threshold of 20 pixels. Success plot shows the percentages of successful frames whose overlap ratio between the predicted bounding box and ground-truth is larger than a certain threshold varied from 0 to 1. AUC will be caluclated on each success plot. All the results are presented with one-pass evaluation (OPE), i.e., a tracker is run throughout a test sequence with initialization from the ground truth position in the initial frame. Related codes are provided in the source code package. </p> </article> <!-- <article class="row post"> <h5>Source Code Link:</h5> <p class="post-body">Evaluation code: <a href="/assets/code/Evaluation.zip">Evaluation.zip</a></p> <p class="post-body">2D image to hyperspectral cube conversion code: <a href="/assets/code/X2Cube.zip">X2Cube.zip</a></p> </article> --> <article class="row post"> <h5>Technical Support:</h5> <p class="post-body">Fengchao Xiong <p>School of Computer Science and Engineering, Nanjing University Science and Technology</p> <p>Email: fcxiong@njust.edu.cn</p> </article> </div> </div> </div> </section> <!-- End Blog --> <footer id="footer" class="footer"> <div class="row"> <div class="pull-left col-md-6 col-xs-6"> <div class="g-plusone" data-size="medium" data-annotation="inline" data-width="300" data-href="http://localhost:4000"></div> </div> <div class="logo logo-footer logo-gray pull-right"></div> </div> <div class="row" style="margin-left: 20%"> </div> <!-- <div class="row"> <div class="col-md-6 col-xs-12"> <ul class="social-links"> </ul> </div> </div> --> <div class="row"> <!-- Please don't delete this line--> <div class="col-md-6"> <p class="copyright"> &copy; 2022 Based on <a href="https://github.com/gdg-x/zeppelin" target="_blank">Project Zeppelin</a>. Designed and created by <a href="http://www.xiongfuli.com/cv" target="_blank">Fengchao Xiong</a> </p> </div> </div> </footer> <!-- End Footer </div> </div> </div> <!-- --> <!-- <script> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','//www.google-analytics.com/analytics.js','ga'); ga('create', 'UA-43643469-5', 'https://www.hsitracking.com'); ga('send', 'pageview'); </script> --> <script src="/js/jquery.min.js"></script> <script> window.jQuery || document.write('<script src="/js/jquery-2.1.1.min.js><\/script>') </script> <script src="/js/bootstrap.min_min.js"></script> <script> if (typeof($.fn.modal) === 'undefined') { document.write('<script src="/js/bootstrap.min.js><\/script>') } </script> <script src="/js/default.js"></script> <!-- --> <script> Waves.displayEffect(); </script> <script src="/js/scripts.js"></script> <!-- <script type="application/ld+json"> [{ "@context" : "http://schema.org", "@type" : "Event", "name" : "Hyperspectral Object Tracking Challenge 2022", "description": "Hyperspectral Object Tracking Challenge 2022", "image" : "http://localhost:4000/img/seo/sharing-google-plus.png", "url" : "http://localhost:4000", "startDate" : "", "doorTime" : "", "endDate" : "", "location" : { "@type" : "Place", "name" : "", "sameAs" : "", "address" : { "@type" : "PostalAddress", "streetAddress" : "", "addressLocality" : "", "addressRegion" : "", "postalCode" : "", "addressCountry" : "" }, "geo" : { "@type" : "GeoCoordinates", "latitude" : "", "longitude" : "" } }, // Not supported yet // "organizer" : { // "@type" : "Organization", // "name" : "GDG Lviv", // "alternateName" : "Google Developer Group Lviv", // "description" : "Open and volunteer geek communities who create exciting projects and share experience about Google technology with passion.", // "logo" : "http://localhost:4000/img/seo/logo2.png", // "email" : "lviv@gdg.org.ua", // "sameAs" : "http://lviv.gdg.org.ua/" // }, "subEvent" : { "@type" : "Event", "name" : "", "description": "", "image" : "http://localhost:4000/img/seo/sharing-google-plus.png", "url" : "http://localhost:4000/hackathon/", "startDate" : "", "doorTime" : "", "endDate" : "", "location" : { "@type" : "Place", "name" : "", "sameAs" : "", "address" : { "@type" : "PostalAddress", "streetAddress" : "", "addressLocality" : "", "addressRegion" : "", "postalCode" : "", "addressCountry" : "" }, "geo" : { "@type" : "GeoCoordinates", "latitude" : "", "longitude" : "" } } }, "offers" : [ ], "performer" : [ { "@type" : "Person", "name" : "Jocelyn Chanussot", "image" : "http://localhost:4000/img/people/Jocelyn.png", "jobTitle" : "Professor", "worksFor" : { "@type" : "Organization", "name" : "Grenoble Institute of Technology, France" }, "sameAs" : "" }, { "@type" : "Person", "name" : "Pedram Ghamisi", "image" : "http://localhost:4000/img/people/Pedram.jpg", "jobTitle" : "Android Developer", "worksFor" : { "@type" : "Organization", "name" : "Helmholtz-Zentrum Dresden-Rossendorf, Germany</br>VasoGnosis, USA" }, "sameAs" : "" }, { "@type" : "Person", "name" : "Yanfei Zhong", "image" : "http://localhost:4000/img/people/zyf.jpeg", "jobTitle" : "Professor", "worksFor" : { "@type" : "Organization", "name" : "Wuhan University, China" }, "sameAs" : "" }, { "@type" : "Person", "name" : "Wouter Charle", "image" : "http://localhost:4000/img/people/wouter.jpeg", "jobTitle" : "Program Manager imec Hyperspectral Imaging", "worksFor" : { "@type" : "Organization", "name" : "Interuniversity Microelectronics Centre, </br> Belgium" }, "sameAs" : "" }, { "@type" : "Person", "name" : "Fengchao Xiong", "image" : "http://localhost:4000/img/people/Fengchao.jpg", "jobTitle" : "Professor", "worksFor" : { "@type" : "Organization", "name" : "Nanjing University of Science and Technology, China" }, "sameAs" : "" }, { "@type" : "Person", "name" : "Jun Zhou", "image" : "http://localhost:4000/img/people/jun.jpg", "jobTitle" : "Professor", "worksFor" : { "@type" : "Organization", "name" : "Griffith University, </br> Australia" }, "sameAs" : "" } ], "eventStatus" : "EventScheduled", "typicalAgeRange" : "16+" }] </script> --></body> </html>
